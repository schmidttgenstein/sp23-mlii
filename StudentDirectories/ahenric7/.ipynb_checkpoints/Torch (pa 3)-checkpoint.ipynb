{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-065c398fe385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch.nn as nn\n",
    "import numpy.linalg as la \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "class MLPipeline:\n",
    "    def __init__(self,epochs = 250,lr = 0.025):\n",
    "        ###In this constructor we set the model complexity, number of epochs for training, \n",
    "        ##and learning rate lr. You should think of complexity here as \"number of parameters\"\n",
    "        #defining model. In linear regression, this e.g. may be (deg of poly)-1. \n",
    "        self.epochs = epochs\n",
    "        self.lr = lr \n",
    "\n",
    "    def gen_data(self,):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def loss(self,):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self,):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self,):\n",
    "        raise NotImplementedError \n",
    "\n",
    "    def update(self,):\n",
    "        raise NotImplementedError  \n",
    "\n",
    "    def metrics(self,x,y):\n",
    "        raise NotImplementedError     \n",
    "\n",
    "    def fit(self,x_data,y_data,x_eval,y_eval, printing = False):\n",
    "        ### This method implements our \"1. forward 2. backward 3. update paradigm\"\n",
    "        ## it should call forward(), grad(), and update(), in that order. \n",
    "        # you should also call metrics so that you may print progress during training\n",
    "        if printing:\n",
    "            self.x_eval = x_eval \n",
    "            self.y_eval = y_eval\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = self.forward(x_data)\n",
    "            loss = self.loss(y_pred,y_data)\n",
    "            grad = self.backward(x_data,y_data)\n",
    "            self.update(grad)\n",
    "            if printing: \n",
    "                m = self.metrics(x_eval,y_eval)\n",
    "                if epoch % 100 == 0:\n",
    "                    print(f\"epoch {epoch} and train loss {loss.mean():.2f}, test metrics {m:.2f}\")\n",
    "        if printing:\n",
    "            self.m = m\n",
    "\n",
    "\n",
    "class FCNetTo(MLPipeline):\n",
    "    def __init__(self,params:list=None,dims:list=None, epoch:int= 250, lr = 0.05,):\n",
    "        super().__init__(epochs = epoch, lr = lr )\n",
    "        if dims is not None:\n",
    "            self.dims = dims \n",
    "        elif params is not None:\n",
    "            weights = params[0]\n",
    "            bias = params[1]\n",
    "            dims = [weights[0].shape[1]]\n",
    "            for w in weights: \n",
    "                dims.append(w.shape[0])\n",
    "        od = OrderedDict()\n",
    "        self.activation = nn.Sigmoid() \n",
    "        for j in range(len(dims)-1):\n",
    "            od[f\"linear_{j}\"] = nn.Linear(dims[j],dims[j+1])\n",
    "            if params is not None:\n",
    "                od[f\"linear_{j}\"].weight = nn.Parameter(torch.tensor(weights[j],requires_grad = True).float())\n",
    "                od[f\"linear_{j}\"].bias = nn.Parameter(torch.tensor(bias[j],requires_grad = True))\n",
    "            od[f\"activation_{j}\"] = self.activation\n",
    "\n",
    "        self.forward_stack = nn.Sequential(od)\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.forward_stack(torch.transpose(x,0,1))\n",
    "\n",
    "class FCNetFS(MLPipeline):\n",
    "    def __init__(self,params:list=None, dims:list=None,epochs:int = 1500,lr = .01,):\n",
    "        super().__init__(epochs = epochs,lr = lr)\n",
    "        if params is None:\n",
    "            weights = []\n",
    "            bias = []\n",
    "            for j in range(int(len(dims)-1)):\n",
    "                w = 10 * (np.random.random([dims[j],dims[j+1]])-.5)\n",
    "                b = 10 * (np.random.random(dims[j+1]) - .5)\n",
    "                weights.append(w)\n",
    "                bias.append(b)\n",
    "        else:\n",
    "            weights = params[0]\n",
    "            bias = params[1]\n",
    "            self.weights = weights \n",
    "            self.bias = bias\n",
    "            dims = [weights[0].shape[0]]\n",
    "            for w in weights: \n",
    "                dims.append(w.shape[0])\n",
    "        self.weights = weights \n",
    "        self.bias = bias \n",
    "        self.dims = dims \n",
    "        self.n_layers = len(dims)\n",
    "\n",
    "    def forward(self,x):\n",
    "        la = self.full_forward(x)\n",
    "        a = la[-1]\n",
    "        return a\n",
    "\n",
    "    def full_forward(self,x):\n",
    "        assert x.shape[0] == self.dims[0], \"Incorrect input dimension!\"\n",
    "        j = 0\n",
    "        a = x \n",
    "        layer_acts = [a]\n",
    "        for weight in self.weights:\n",
    "            z_pre = weight @  a \n",
    "            z = z_pre + self.bias[j]\n",
    "            if j < self.n_layers - 1:\n",
    "                a = self.activation(z)\n",
    "            else: \n",
    "                a = z\n",
    "            layer_acts.append(a)\n",
    "            j+=1\n",
    "        return layer_acts\n",
    "\n",
    "    def backward(self,x_in,y_truth):\n",
    "        return None\n",
    "\n",
    "    def update(self,grad):\n",
    "        return None\n",
    "\n",
    "\n",
    "    def metrics(self,x,y):\n",
    "        return None\n",
    "\n",
    "    def activation(self,z):\n",
    "        return self.sigmoid(z)\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def loss(self,x_in,y_truth):\n",
    "        ### calculating loss using partial as initial computation\n",
    "        return None\n",
    "\n",
    "    def l_grad(self,x_in,y_truth):\n",
    "        ### partial loss / partial y_pred \n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #Step 0: No errors here, insantiate a network and \"look at it\" (you can skip)\n",
    "    onet = FCNetFS(dims = [1,2,3,1])\n",
    "    onet.weights\n",
    "    onet.bias \n",
    "    onet.dims \n",
    "    \n",
    "    #Step 1: Generate \"From Scratch\" Network and Instantiate Torch Network with these weights\n",
    "    anet = FCNetFS(dims = [1,5,3,5,1],epochs = 250, lr = 0.01)\n",
    "    in_params = anet.weights\n",
    "    print(in_params)\n",
    "    bnet = FCNetTo(params=in_params)\n",
    "    #Before continuing, examine your bnet.forward_stack to ensure that layers are coordinated as you \n",
    "    n_samp = 350\n",
    "    tspace = np.linspace(-15,15,n_samp)\n",
    "    y1 =  anet.forward(tspace)\n",
    "    y2 = bnet.forward(tspace)\n",
    "    #Step 1.5 sanity check: can you reproduce From Scratch network with prespecified weights params?\n",
    "    a2net = FCNetFS(params=in_params)\n",
    "    y3 = a2net.forward(tspace) \n",
    "    plt.figure(1)\n",
    "    plt.plot(tspace.flatten(),y1.flatten())\n",
    "    plt.plot(tspace.flatten(),y2.detach().numpy(),'--')\n",
    "    plt.figure(2)\n",
    "    plt.plot(tspace.flatten(),np.abs(y1.flatten()-y2.detach().numpy().flatten())+np.abs(y1.flatten()-y3.flatten()))\n",
    "    \n",
    "\n",
    "    #Step 2: Generate \"To[rch]\" Network and Instantiate from scratch network with these weights\n",
    "    cnet = FCNetTo(dims = [1,7,5,7,1])\n",
    "    weights = []\n",
    "    bias = []\n",
    "    for layer in cnet.forward_stack:\n",
    "        if isinstance(layer,nn.Linear):\n",
    "            weights.append(layer.weight.detach())\n",
    "    params = [weights,bias]\n",
    "    dnet = FCNetFS(params)\n",
    "\n",
    "    y3 =  cnet.forward(torch.tensor(tspace).float())\n",
    "    y4 = dnet.forward(tspace)\n",
    "    plt.figure(3)\n",
    "    plt.plot(tspace.flatten(),y4.flatten())\n",
    "    plt.plot(tspace.flatten(),y3.detach().numpy(),'--')\n",
    "    plt.figure(4)\n",
    "    plt.plot(tspace.flatten(),np.abs(y4.flatten()-y3.detach().numpy().flatten()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
